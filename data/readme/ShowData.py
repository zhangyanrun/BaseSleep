# import numpy as np
# import logging

# # 1. é…ç½®æ—¥å¿—è®¾ç½®
# # filename: æ—¥å¿—æ–‡ä»¶å
# # level: è®°å½•çº§åˆ« (INFO è¡¨ç¤ºè®°å½•ä¸€èˆ¬ä¿¡æ¯)
# # format: æ—¥å¿—çš„æ ¼å¼ (æ—¶é—´ - çº§åˆ« - å†…å®¹)
# logging.basicConfig(
#     filename='data_process.log', 
#     level=logging.INFO,
#     format='%(asctime)s - %(levelname)s - %(message)s',
#     datefmt='%Y-%m-%d %H:%M:%S'
# )

# try:
#     # 2. åŠ è½½æ•°æ®
#     data = np.load('Milan.npy')

#     # 3. æ‹¼æ¥è¦è®°å½•çš„æ ¼å¼ä¿¡æ¯
#     # å»ºè®®è®°å½•ï¼šå½¢çŠ¶ã€æ•°æ®ç±»å‹ã€å ç”¨å†…å­˜å¤§å°ã€ç»´åº¦
#     log_msg = (
#         f"æ•°æ®åŠ è½½æˆåŠŸã€‚\n"
#         f"    - å½¢çŠ¶ (Shape): {data.shape}\n"
#         f"    - ç±»å‹ (Dtype): {data.dtype}\n"
#         f"    - ç»´åº¦ (Ndim):  {data.ndim}\n"
#         f"    - å…ƒç´ æ€»æ•° (Size): {data.size}"
#     )

#     # 4. å†™å…¥æ—¥å¿—
#     logging.info(log_msg)
#     print("æ—¥å¿—å†™å…¥å®Œæˆã€‚")

# except Exception as e:
#     # å¦‚æœå‡ºé”™ï¼Œä¹Ÿå¯ä»¥è®°å½•é”™è¯¯æ—¥å¿—
#     logging.error(f"è¯»å–æ–‡ä»¶å¤±è´¥: {e}")



### æŸ¥çœ‹network_env_dataset.pkl
import pickle
import pandas as pd
import numpy as np
import os

def inspect_dataset(file_path='network_env_dataset.pkl'):
    """
    æ·±åº¦æ£€æŸ¥ PKL æ•°æ®é›†æ–‡ä»¶çš„å†…å®¹ã€ç»´åº¦å’Œç‰©ç†æ„ä¹‰ã€‚
    """
    print(f"\n{'='*40}")
    print(f"ğŸ” æ­£åœ¨æ£€æŸ¥æ–‡ä»¶: {file_path}")
    print(f"{'='*40}")

    if not os.path.exists(file_path):
        print(f"âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°æ–‡ä»¶ {file_path}")
        return

    try:
        with open(file_path, 'rb') as f:
            dataset = pickle.load(f)
    except Exception as e:
        print(f"âŒ è¯»å–å¤±è´¥: {e}")
        return

    # 1. å…¨å±€æ¦‚è§ˆ
    mesh_keys = list(dataset.keys())
    print(f"âœ… è¯»å–æˆåŠŸï¼")
    print(f"ğŸ“Š æ•°æ®é›†åŒ…å« Mesh æ•°é‡: {len(mesh_keys)}")
    print(f"ğŸ”‘ Mesh ID ç¤ºä¾‹: {mesh_keys[:10]} ...")

    # 2. æŠ½å–ç¬¬ä¸€ä¸ª Mesh è¿›è¡Œæ·±åº¦æ£€æŸ¥ (é€šå¸¸æ˜¯ Mesh 0)
    target_mesh = mesh_keys[0]
    print(f"\n{'-'*20} æ­£åœ¨æ·±å…¥æ£€æŸ¥ Mesh {target_mesh} {'-'*20}")
    
    data = dataset[target_mesh]
    
    # --- A. å®Œæ•´æ€§æ£€æŸ¥ ---
    bs_ids = data['bs_ids']
    num_bs = len(bs_ids)
    print(f"1. [åŸºç«™åˆ—è¡¨] (æ•°é‡: {num_bs})")
    print(f"   IDs: {bs_ids}")

    # --- B. æµé‡å¼ é‡æ£€æŸ¥ ---
    tensor = data['traffic_tensor']
    print(f"\n2. [æµé‡å¼ é‡ Traffic Tensor]")
    print(f"   Shape: {tensor.shape} (Time, BS, Feature)")
    
    # ç»´åº¦æ ¡éªŒ
    if tensor.shape[1] != num_bs:
        print(f"   âŒ è­¦å‘Šï¼šå¼ é‡ç¬¬2ç»´ ({tensor.shape[1]}) ä¸åŸºç«™æ•°é‡ ({num_bs}) ä¸ä¸€è‡´ï¼(å¯èƒ½æœ‰è„æ•°æ®)")
    else:
        print(f"   âœ… ç»´åº¦æ ¡éªŒé€šè¿‡ï¼šæ—¶é—´æ­¥={tensor.shape[0]}, åŸºç«™æ•°={tensor.shape[1]}")
        
    # æ•°å€¼èŒƒå›´æ£€æŸ¥
    print(f"   Max Load: {np.max(tensor):.4f}, Min Load: {np.min(tensor):.4f} (åº”åœ¨ 0~1 ä¹‹é—´)")

    # --- C. é‚»æ¥çŸ©é˜µæ£€æŸ¥ ---
    adj = data['adj_matrix']
    print(f"\n3. [é‚»æ¥çŸ©é˜µ Adjacency Matrix]")
    print(f"   Shape: {adj.shape}")
    
    # è½¬ä¸º DataFrame æ–¹ä¾¿æŸ¥çœ‹
    df_adj = pd.DataFrame(adj, index=bs_ids, columns=bs_ids)
    
    # è®¾ç½® Pandas æ˜¾ç¤ºé€‰é¡¹ (é˜²æ­¢æ‰“å°ä¸å…¨)
    pd.set_option('display.max_columns', 20)
    pd.set_option('display.width', 1000)
    pd.set_option('display.precision', 0)
    
    print("\n   --- çŸ©é˜µé¢„è§ˆ (1=åˆ—è¦†ç›–è¡Œ, 0=ä¸å¯è¦†ç›–) ---")
    print(df_adj)
    
    # --- D. è¦†ç›–é€»è¾‘ç»Ÿè®¡ ---
    # è®¡ç®—æ¯ä¸ªåŸºç«™è¢«å¤šå°‘ä¸ªâ€œå…¶ä»–åŸºç«™â€è¦†ç›– (Row Sum - 1)
    covered_counts = np.sum(adj, axis=1) - 1
    avg_coverage = np.mean(covered_counts)
    
    print(f"\n   --- è¦†ç›–ç»Ÿè®¡ ---")
    print(f"   å¹³å‡æ¯ä¸ªåŸºç«™å¯è¢« {avg_coverage:.2f} ä¸ªé‚»å±…æ¥ç®¡")
    
    # æ‰¾å‡ºå­¤ç«‹ç‚¹
    isolated = np.where(covered_counts == 0)[0]
    if len(isolated) > 0:
        print(f"   âš ï¸ æ³¨æ„ï¼šæœ‰ {len(isolated)} ä¸ªåŸºç«™æ— æ³•è¢«ä»»ä½•é‚»å±…è¦†ç›– (åªèƒ½è‡ªå·±è¦†ç›–è‡ªå·±):")
        print(f"   -> IDs: {bs_ids[isolated]}")
    else:
        print(f"   âœ… æ‰€æœ‰åŸºç«™è‡³å°‘æœ‰ä¸€ä¸ªé‚»å±…å¯ä»¥æ¥ç®¡å®ƒã€‚")

    # --- E. é™æ€ä¿¡æ¯é¢„è§ˆ ---
    print(f"\n4. [é™æ€ä¿¡æ¯ Static Info]")
    print(data['static_info'].head())

if __name__ == "__main__":
    inspect_dataset()